#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›½ç½‘é£æ§æ•°ä»“ - å»¶è¿Ÿç›‘æ§å’Œæ€§èƒ½æµ‹è¯•è„šæœ¬
å®æ—¶ç›‘æ§æ•°æ®ä¼ è¾“å»¶è¿Ÿå’Œç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
"""

import psycopg2
import time
import json
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import statistics
from dataclasses import dataclass
import signal
import sys

@dataclass
class LatencyMetric:
    """å»¶è¿ŸæŒ‡æ ‡æ•°æ®ç±»"""
    timestamp: datetime
    source_time: Optional[datetime]
    sink_time: Optional[datetime]
    latency_seconds: Optional[float]
    record_count: int
    table_name: str

class LatencyMonitor:
    """å»¶è¿Ÿç›‘æ§å™¨"""
    
    def __init__(self, source_config: Dict[str, Any], sink_config: Dict[str, Any]):
        self.source_config = source_config
        self.sink_config = sink_config
        self.metrics: List[LatencyMetric] = []
        self.running = False
        self.lock = threading.Lock()
        
        # ç›‘æ§é…ç½®
        self.monitor_interval = 10  # ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰
        self.max_metrics = 1000     # æœ€å¤§ä¿å­˜æŒ‡æ ‡æ•°é‡
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
    
    def signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨"""
        print("\næ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
        self.stop_monitoring()
        sys.exit(0)
    
    def get_connection(self, config: Dict[str, Any]):
        """è·å–æ•°æ®åº“è¿æ¥"""
        return psycopg2.connect(
            host=config['host'],
            port=config['port'],
            database=config['database'],
            user=config['user'],
            password=config['password']
        )
    
    def measure_table_latency(self, source_table: str, sink_table: str, 
                            source_time_col: str, sink_time_col: str) -> LatencyMetric:
        """æµ‹é‡ç‰¹å®šè¡¨çš„å»¶è¿Ÿ"""
        source_conn = None
        sink_conn = None
        
        try:
            # è¿æ¥æ•°æ®åº“
            source_conn = self.get_connection(self.source_config)
            sink_conn = self.get_connection(self.sink_config)
            
            source_cursor = source_conn.cursor()
            sink_cursor = sink_conn.cursor()
            
            # è·å–sourceç«¯æœ€æ–°æ•°æ®
            source_cursor.execute(f"""
                SELECT MAX({source_time_col}) as latest_time, COUNT(*) as record_count
                FROM {source_table}
                WHERE {source_time_col} > NOW() - INTERVAL '1 hour'
            """)
            source_result = source_cursor.fetchone()
            source_time = source_result[0] if source_result[0] else None
            source_count = source_result[1] if source_result[1] else 0
            
            # è·å–sinkç«¯æœ€æ–°æ•°æ®
            sink_cursor.execute(f"""
                SELECT MAX({sink_time_col}) as latest_time, COUNT(*) as record_count
                FROM {sink_table}
                WHERE {sink_time_col} > NOW() - INTERVAL '1 hour'
            """)
            sink_result = sink_cursor.fetchone()
            sink_time = sink_result[0] if sink_result[0] else None
            sink_count = sink_result[1] if sink_result[1] else 0
            
            # è®¡ç®—å»¶è¿Ÿ
            latency = None
            if source_time and sink_time:
                latency = (sink_time - source_time).total_seconds()
            
            return LatencyMetric(
                timestamp=datetime.now(),
                source_time=source_time,
                sink_time=sink_time,
                latency_seconds=latency,
                record_count=max(source_count, sink_count),
                table_name=f"{source_table}->{sink_table}"
            )
            
        except Exception as e:
            print(f"æµ‹é‡å»¶è¿Ÿå¤±è´¥ {source_table}->{sink_table}: {e}")
            return LatencyMetric(
                timestamp=datetime.now(),
                source_time=None,
                sink_time=None,
                latency_seconds=None,
                record_count=0,
                table_name=f"{source_table}->{sink_table}"
            )
        finally:
            if source_conn:
                source_conn.close()
            if sink_conn:
                sink_conn.close()
    
    def measure_end_to_end_latency(self) -> List[LatencyMetric]:
        """æµ‹é‡ç«¯åˆ°ç«¯å»¶è¿Ÿ"""
        metrics = []
        
        # å®šä¹‰ç›‘æ§çš„è¡¨æ˜ å°„å…³ç³»
        table_mappings = [
            {
                'source_table': 'power_consumption',
                'sink_table': 'ads_realtime_dashboard',
                'source_time_col': 'created_at',
                'sink_time_col': 'update_time'
            },
            {
                'source_table': 'equipment_status',
                'sink_table': 'ads_equipment_health',
                'source_time_col': 'created_at',
                'sink_time_col': 'analysis_time'
            },
            {
                'source_table': 'power_consumption',
                'sink_table': 'ads_power_quality',
                'source_time_col': 'created_at',
                'sink_time_col': 'analysis_time'
            },
            {
                'source_table': 'alert_records',
                'sink_table': 'ads_alert_statistics',
                'source_time_col': 'created_at',
                'sink_time_col': 'stat_time'
            }
        ]
        
        for mapping in table_mappings:
            metric = self.measure_table_latency(
                mapping['source_table'],
                mapping['sink_table'],
                mapping['source_time_col'],
                mapping['sink_time_col']
            )
            metrics.append(metric)
        
        return metrics
    
    def get_system_metrics(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        source_conn = None
        sink_conn = None
        
        try:
            source_conn = self.get_connection(self.source_config)
            sink_conn = self.get_connection(self.sink_config)
            
            source_cursor = source_conn.cursor()
            sink_cursor = sink_conn.cursor()
            
            # Sourceç«¯æŒ‡æ ‡
            source_cursor.execute("""
                SELECT 
                    'source' as db_type,
                    COUNT(*) as total_connections,
                    SUM(CASE WHEN state = 'active' THEN 1 ELSE 0 END) as active_connections
                FROM pg_stat_activity 
                WHERE datname = current_database()
            """)
            source_stats = source_cursor.fetchone()
            
            # è·å–sourceç«¯è¡¨å¤§å°
            source_cursor.execute("""
                SELECT 
                    schemaname,
                    tablename,
                    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
                    pg_total_relation_size(schemaname||'.'||tablename) as size_bytes
                FROM pg_tables 
                WHERE schemaname = 'public'
                ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
            """)
            source_table_sizes = source_cursor.fetchall()
            
            # Sinkç«¯æŒ‡æ ‡
            sink_cursor.execute("""
                SELECT 
                    'sink' as db_type,
                    COUNT(*) as total_connections,
                    SUM(CASE WHEN state = 'active' THEN 1 ELSE 0 END) as active_connections
                FROM pg_stat_activity 
                WHERE datname = current_database()
            """)
            sink_stats = sink_cursor.fetchone()
            
            # è·å–sinkç«¯è¡¨å¤§å°
            sink_cursor.execute("""
                SELECT 
                    schemaname,
                    tablename,
                    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
                    pg_total_relation_size(schemaname||'.'||tablename) as size_bytes
                FROM pg_tables 
                WHERE schemaname = 'public'
                ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
            """)
            sink_table_sizes = sink_cursor.fetchall()
            
            return {
                'timestamp': datetime.now().isoformat(),
                'source_db': {
                    'total_connections': source_stats[1],
                    'active_connections': source_stats[2],
                    'table_sizes': [{
                        'schema': row[0],
                        'table': row[1],
                        'size_pretty': row[2],
                        'size_bytes': row[3]
                    } for row in source_table_sizes]
                },
                'sink_db': {
                    'total_connections': sink_stats[1],
                    'active_connections': sink_stats[2],
                    'table_sizes': [{
                        'schema': row[0],
                        'table': row[1],
                        'size_pretty': row[2],
                        'size_bytes': row[3]
                    } for row in sink_table_sizes]
                }
            }
            
        except Exception as e:
            return {'error': str(e), 'timestamp': datetime.now().isoformat()}
        finally:
            if source_conn:
                source_conn.close()
            if sink_conn:
                sink_conn.close()
    
    def calculate_statistics(self, window_minutes: int = 10) -> Dict[str, Any]:
        """è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡"""
        with self.lock:
            # è·å–æŒ‡å®šæ—¶é—´çª—å£å†…çš„æŒ‡æ ‡
            cutoff_time = datetime.now() - timedelta(minutes=window_minutes)
            recent_metrics = [m for m in self.metrics if m.timestamp > cutoff_time]
        
        if not recent_metrics:
            return {'error': 'æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œç»Ÿè®¡'}
        
        # æŒ‰è¡¨åˆ†ç»„è®¡ç®—ç»Ÿè®¡
        table_stats = {}
        for table_name in set(m.table_name for m in recent_metrics):
            table_metrics = [m for m in recent_metrics if m.table_name == table_name]
            latencies = [m.latency_seconds for m in table_metrics if m.latency_seconds is not None]
            
            if latencies:
                table_stats[table_name] = {
                    'count': len(latencies),
                    'avg_latency': statistics.mean(latencies),
                    'min_latency': min(latencies),
                    'max_latency': max(latencies),
                    'median_latency': statistics.median(latencies),
                    'std_latency': statistics.stdev(latencies) if len(latencies) > 1 else 0
                }
        
        # æ•´ä½“ç»Ÿè®¡
        all_latencies = [m.latency_seconds for m in recent_metrics if m.latency_seconds is not None]
        overall_stats = {}
        if all_latencies:
            overall_stats = {
                'total_measurements': len(all_latencies),
                'avg_latency': statistics.mean(all_latencies),
                'min_latency': min(all_latencies),
                'max_latency': max(all_latencies),
                'median_latency': statistics.median(all_latencies),
                'p95_latency': sorted(all_latencies)[int(len(all_latencies) * 0.95)] if len(all_latencies) > 20 else max(all_latencies),
                'p99_latency': sorted(all_latencies)[int(len(all_latencies) * 0.99)] if len(all_latencies) > 100 else max(all_latencies)
            }
        
        return {
            'window_minutes': window_minutes,
            'timestamp': datetime.now().isoformat(),
            'overall_stats': overall_stats,
            'table_stats': table_stats
        }
    
    def print_real_time_stats(self):
        """æ‰“å°å®æ—¶ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.calculate_statistics(window_minutes=5)
        system_metrics = self.get_system_metrics()
        
        # æ¸…å±
        print("\033[2J\033[H", end="")
        
        print("="*80)
        print("           å›½ç½‘é£æ§æ•°ä»“ - å®æ—¶å»¶è¿Ÿç›‘æ§")
        print(f"           ç›‘æ§æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80)
        
        # æ•´ä½“ç»Ÿè®¡
        if 'overall_stats' in stats and stats['overall_stats']:
            overall = stats['overall_stats']
            print(f"\nğŸ“Š æ•´ä½“å»¶è¿Ÿç»Ÿè®¡ (æœ€è¿‘5åˆ†é’Ÿ):")
            print(f"   æµ‹é‡æ¬¡æ•°: {overall['total_measurements']}")
            print(f"   å¹³å‡å»¶è¿Ÿ: {overall['avg_latency']:.2f} ç§’")
            print(f"   æœ€å°å»¶è¿Ÿ: {overall['min_latency']:.2f} ç§’")
            print(f"   æœ€å¤§å»¶è¿Ÿ: {overall['max_latency']:.2f} ç§’")
            print(f"   ä¸­ä½å»¶è¿Ÿ: {overall['median_latency']:.2f} ç§’")
            if 'p95_latency' in overall:
                print(f"   P95å»¶è¿Ÿ:  {overall['p95_latency']:.2f} ç§’")
            if 'p99_latency' in overall:
                print(f"   P99å»¶è¿Ÿ:  {overall['p99_latency']:.2f} ç§’")
        
        # åˆ†è¡¨ç»Ÿè®¡
        if 'table_stats' in stats and stats['table_stats']:
            print(f"\nğŸ“ˆ åˆ†è¡¨å»¶è¿Ÿç»Ÿè®¡:")
            for table_name, table_stat in stats['table_stats'].items():
                print(f"   {table_name}:")
                print(f"     å¹³å‡: {table_stat['avg_latency']:.2f}s | "
                      f"æœ€å°: {table_stat['min_latency']:.2f}s | "
                      f"æœ€å¤§: {table_stat['max_latency']:.2f}s")
        
        # ç³»ç»ŸæŒ‡æ ‡
        if 'error' not in system_metrics:
            print(f"\nğŸ–¥ï¸  ç³»ç»ŸæŒ‡æ ‡:")
            source_db = system_metrics['source_db']
            sink_db = system_metrics['sink_db']
            print(f"   Source DB: {source_db['active_connections']}/{source_db['total_connections']} æ´»è·ƒè¿æ¥")
            print(f"   Sink DB:   {sink_db['active_connections']}/{sink_db['total_connections']} æ´»è·ƒè¿æ¥")
            
            # æ˜¾ç¤ºæœ€å¤§çš„å‡ ä¸ªè¡¨
            print(f"\nğŸ’¾ è¡¨å¤§å° (Top 3):")
            print(f"   Sourceç«¯:")
            for table in source_db['table_sizes'][:3]:
                print(f"     {table['table']}: {table['size_pretty']}")
            print(f"   Sinkç«¯:")
            for table in sink_db['table_sizes'][:3]:
                print(f"     {table['table']}: {table['size_pretty']}")
        
        # æœ€æ–°å»¶è¿Ÿ
        with self.lock:
            if self.metrics:
                latest_metrics = self.metrics[-4:]  # æ˜¾ç¤ºæœ€æ–°4æ¡
                print(f"\nâ±ï¸  æœ€æ–°å»¶è¿Ÿæµ‹é‡:")
                for metric in latest_metrics:
                    if metric.latency_seconds is not None:
                        print(f"   {metric.timestamp.strftime('%H:%M:%S')} | "
                              f"{metric.table_name}: {metric.latency_seconds:.2f}s")
        
        print(f"\næŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        print("="*80)
    
    def monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.running:
            try:
                # æµ‹é‡å»¶è¿Ÿ
                new_metrics = self.measure_end_to_end_latency()
                
                with self.lock:
                    self.metrics.extend(new_metrics)
                    # ä¿æŒæŒ‡æ ‡æ•°é‡åœ¨é™åˆ¶å†…
                    if len(self.metrics) > self.max_metrics:
                        self.metrics = self.metrics[-self.max_metrics:]
                
                # æ‰“å°å®æ—¶ç»Ÿè®¡
                self.print_real_time_stats()
                
                # ç­‰å¾…ä¸‹æ¬¡ç›‘æ§
                time.sleep(self.monitor_interval)
                
            except Exception as e:
                print(f"ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                time.sleep(5)
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        print("å¼€å§‹å»¶è¿Ÿç›‘æ§...")
        self.running = True
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(target=self.monitor_loop)
        monitor_thread.daemon = True
        monitor_thread.start()
        
        try:
            # ä¸»çº¿ç¨‹ç­‰å¾…
            while self.running:
                time.sleep(1)
        except KeyboardInterrupt:
            self.stop_monitoring()
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        print("\nåœæ­¢ç›‘æ§...")
        self.running = False
        
        # ä¿å­˜æœ€ç»ˆç»Ÿè®¡
        final_stats = self.calculate_statistics(window_minutes=60)
        
        print("\n" + "="*60)
        print("           æœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š")
        print("="*60)
        
        if 'overall_stats' in final_stats and final_stats['overall_stats']:
            overall = final_stats['overall_stats']
            print(f"\nğŸ“Š æ•´ä½“æ€§èƒ½ (æœ€è¿‘1å°æ—¶):")
            print(f"   æ€»æµ‹é‡æ¬¡æ•°: {overall['total_measurements']}")
            print(f"   å¹³å‡å»¶è¿Ÿ: {overall['avg_latency']:.2f} ç§’")
            print(f"   æœ€ä½³å»¶è¿Ÿ: {overall['min_latency']:.2f} ç§’")
            print(f"   æœ€å·®å»¶è¿Ÿ: {overall['max_latency']:.2f} ç§’")
            print(f"   ä¸­ä½å»¶è¿Ÿ: {overall['median_latency']:.2f} ç§’")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = f"latency_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump({
                'final_stats': final_stats,
                'all_metrics': [{
                    'timestamp': m.timestamp.isoformat(),
                    'table_name': m.table_name,
                    'latency_seconds': m.latency_seconds,
                    'record_count': m.record_count
                } for m in self.metrics]
            }, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        print("ç›‘æ§ç»“æŸã€‚")

def main():
    """ä¸»å‡½æ•°"""
    # æ•°æ®åº“é…ç½®
    source_config = {
        'host': 'localhost',
        'port': 5432,
        'database': 'source_db',
        'user': 'postgres',
        'password': 'postgres'
    }
    
    sink_config = {
        'host': 'localhost',
        'port': 5433,
        'database': 'sink_db',
        'user': 'postgres',
        'password': 'postgres'
    }
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = LatencyMonitor(source_config, sink_config)
    
    # å¼€å§‹ç›‘æ§
    monitor.start_monitoring()

if __name__ == "__main__":
    main()